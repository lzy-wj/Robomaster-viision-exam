# CIFAR-10 å›¾åƒåˆ†ç±»æ™ºèƒ½ä¼˜åŒ–è®­ç»ƒæ¡†æ¶

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ª**CIFAR-10å›¾åƒåˆ†ç±»è®­ç»ƒæ¡†æ¶**ï¼Œé›†æˆäº†**æ™ºèƒ½ç¡¬ä»¶æ£€æµ‹ã€è‡ªé€‚åº”æ¨¡å‹é€‰æ‹©ã€å¤šGPUä¼˜åŒ–è°ƒåº¦**ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚é¡¹ç›®çš„è®¾è®¡ç†å¿µæ˜¯è®©æ·±åº¦å­¦ä¹ è®­ç»ƒå˜å¾—**æ›´ç®€å•ã€æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆ**ã€‚æœ€ä½³å‡†ç¡®ç‡: 0.9451ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- **ğŸ§  æ™ºèƒ½ç¡¬ä»¶æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ«GPUé…ç½®ï¼ŒåŒ…æ‹¬å‹å·ã€æ•°é‡ã€æ˜¾å­˜å®¹é‡
- **âš¡ åŠ¨æ€æ¨¡å‹é€‰æ‹©**: æ ¹æ®ç¡¬ä»¶èƒ½åŠ›è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹æ¶æ„
- **ğŸš€ å¤šGPUæ™ºèƒ½è°ƒåº¦**: è‡ªåŠ¨ç»„åˆåŒå‹å·GPUï¼Œé¿å…æ··åˆä½¿ç”¨å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆ
- **ğŸ“Š å‚æ•°è‡ªé€‚åº”ä¼˜åŒ–**: æ™ºèƒ½æ¨èæ‰¹æ¬¡å¤§å°ã€å­¦ä¹ ç‡ã€æ•°æ®åŠ è½½å‚æ•°
- **ğŸ› ï¸ ç¨³å®šæ€§å¢å¼º**: é’ˆå¯¹å¸¸è§é—®é¢˜æä¾›äº†å¤šé‡ä¿æŠ¤æœºåˆ¶
- **ğŸ“ˆ å®æ—¶ç›‘æ§**: è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾ç¤ºè¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡å’Œç¡¬ä»¶çŠ¶æ€

### ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
ç¬¬å…­éƒ¨åˆ†/
â”œâ”€â”€ train.py              # ä¸»è®­ç»ƒè„šæœ¬ (æ ¸å¿ƒå…¥å£)
â”œâ”€â”€ models.py             # æ¨¡å‹å®šä¹‰ (SmallCifarNet & PowerCifarNet)
â”œâ”€â”€ requirements.txt      # Pythonä¾èµ–åŒ…
â”œâ”€â”€ test.sh              # è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
â”œâ”€â”€ README.md            # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ data/                # æ•°æ®é›†ç›®å½•
â”‚   â””â”€â”€ cifar-10-batches-py/
â””â”€â”€ runs/                # è®­ç»ƒè¾“å‡ºç›®å½•
    â””â”€â”€ cifar10_optimized/
        â”œâ”€â”€ best_model.pth         # æœ€ä½³æ¨¡å‹æƒé‡
        â”œâ”€â”€ training_history.json  # è®­ç»ƒå†å²æ•°æ®
        â””â”€â”€ training_curves.png    # å¯è§†åŒ–è®­ç»ƒæ›²çº¿
```

## ğŸ”„ æ™ºèƒ½è®­ç»ƒæµç¨‹

å½“æ‚¨è¿è¡Œ `python train.py` æ—¶ï¼Œæ¡†æ¶ä¼šè‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹10æ­¥ä¼˜åŒ–æµç¨‹ï¼š

```mermaid
flowchart TD
    A[å¯åŠ¨è®­ç»ƒ] --> B[ç¡¬ä»¶ç¯å¢ƒæ£€æµ‹]
    B --> C{GPUå¯ç”¨?}
    C -->|æ˜¯| D[GPUé…ç½®åˆ†æ]
    C -->|å¦| E[CPUæ¨¡å¼]
    D --> F[æ™ºèƒ½GPUåˆ†ç»„]
    F --> G[æ¨¡å‹æ¶æ„é€‰æ‹©]
    G --> H[å‚æ•°è‡ªé€‚åº”ä¼˜åŒ–]
    H --> I[æ•°æ®åŠ è½½å™¨é…ç½®]
    I --> J[è®­ç»ƒæ‰§è¡Œ]
    J --> K[ç»“æœä¿å­˜]
    E --> G
```

### ğŸ“‹ è¯¦ç»†æµç¨‹è¯´æ˜

#### æ­¥éª¤1-2: å¯åŠ¨ä¸ç¡¬ä»¶æ£€æµ‹

```python
# è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶é…ç½®
hw_config = auto_detect_hardware()
```

- ğŸ” æ£€æµ‹CUDAç¯å¢ƒæ˜¯å¦å¯ç”¨
- ğŸ“Š ç»Ÿè®¡GPUæ•°é‡ã€å‹å·å’Œæ˜¾å­˜å®¹é‡
- ğŸ’¾ è®¡ç®—æ€»æ˜¾å­˜å’Œå•å¡æ˜¾å­˜
- âš¡ è¯„ä¼°ç¡¬ä»¶ç®—åŠ›ç­‰çº§

#### æ­¥éª¤3-4: GPUæ™ºèƒ½åˆ†ç»„

```python
# æ™ºèƒ½é€‰æ‹©åŒå‹å·GPUç»„åˆ
gpu_names = [torch.cuda.get_device_name(i) for i in range(num_gpus)]
most_common_gpu = Counter(gpu_names).most_common(1)[0][0]
device_ids = [i for i, name in enumerate(gpu_names) if name == most_common_gpu]
```

- ğŸ¯  è‡ªåŠ¨è¯†åˆ«å¹¶é€‰æ‹©æ•°é‡æœ€å¤šçš„åŒå‹å·GPU
- ğŸš€ é¿å…æ··åˆGPUå¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆï¼ˆå¦‚A6000+3090æ··åˆï¼‰
- ğŸ® ç¡®ä¿å‚ä¸è®­ç»ƒçš„GPUæ€§èƒ½å®Œå…¨ä¸€è‡´

#### æ­¥éª¤5: åŠ¨æ€æ¨¡å‹é€‰æ‹©

```python
# æ ¹æ®ç¡¬ä»¶èƒ½åŠ›é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹
if hw_config['num_gpus'] >= 3 and hw_config['total_memory_gb'] >= 60:
    model = PowerCifarNet(num_classes=10, width_mult=2.5)  # å¤§æ¨¡å‹
elif hw_config['num_gpus'] >= 2 or hw_config['total_memory_gb'] >= 40:
    model = PowerCifarNet(num_classes=10, width_mult=1.5)  # ä¸­æ¨¡å‹
else:
    model = SmallCifarNet(num_classes=10)  # è½»é‡æ¨¡å‹
```

- ğŸ§  **SmallCifarNet**: ~1.2Må‚æ•°ï¼Œé€‚åˆå•GPUæˆ–ä½æ˜¾å­˜ç¯å¢ƒ
- âš¡ **PowerCifarNet**: 2-10M+å‚æ•°ï¼Œæ·±åº¦æ›´æ·±ã€è¡¨è¾¾èƒ½åŠ›æ›´å¼º

#### æ­¥éª¤6-7: å‚æ•°è‡ªé€‚åº”ä¼˜åŒ–

```python
# æ™ºèƒ½æ¨èè®­ç»ƒå‚æ•°
if total_memory_gb >= 60:
    recommended_batch_size = 512
    recommended_workers = 16
elif total_memory_gb >= 40:
    recommended_batch_size = 384
    recommended_workers = 12
# ...
```

- ğŸ“Š æ ¹æ®GPUæ˜¾å­˜æ™ºèƒ½æ¨èæ‰¹æ¬¡å¤§å°
- ğŸ”„ è‡ªåŠ¨è°ƒæ•´æ•°æ®åŠ è½½å™¨è¿›ç¨‹æ•°
- ğŸ“ˆ å­¦ä¹ ç‡è‡ªåŠ¨ç¼©æ”¾ï¼ˆä¸æ‰¹æ¬¡å¤§å°æˆæ¯”ä¾‹ï¼‰

#### æ­¥éª¤8-10: è®­ç»ƒæ‰§è¡Œä¸ç»“æœä¿å­˜

- ğŸƒ å¯åŠ¨è®­ç»ƒå¾ªç¯ï¼Œå®æ—¶ç›‘æ§æ€§èƒ½æŒ‡æ ‡
- ğŸ’¾ è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹æƒé‡å’Œè®­ç»ƒå†å²
- ğŸ“Š ç”Ÿæˆè®­ç»ƒæ›²çº¿å¯è§†åŒ–å›¾è¡¨

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

1.**å®‰è£…Pythonä¾èµ–**

```bash
# å»ºè®®å…ˆåˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
# å®‰è£…ä¾èµ–åŒ…
pip install -r requirements.txt
```

 2.**éªŒè¯PyTorchå®‰è£…**

```bash
python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
```

### ğŸ§ª ç¯å¢ƒéªŒè¯ï¼ˆæ¨èï¼‰

è¿è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯ç¯å¢ƒé…ç½®æ­£ç¡®æ€§ï¼š

```bash
# Linux/Mac
bash test.sh

# Windows (ä½¿ç”¨Git Bashæˆ–WSL)
bash test.sh
# æˆ–è€…ç›´æ¥è¿è¡ŒPythonå‘½ä»¤
python train.py --epochs 2 --out-dir runs/test
```

**æµ‹è¯•è„šæœ¬åŠŸèƒ½**:

- âœ… æ£€æŸ¥Pythonç‰ˆæœ¬å…¼å®¹æ€§
- âœ… éªŒè¯ä¾èµ–åŒ…å®Œæ•´æ€§
- âœ… æµ‹è¯•GPUç¯å¢ƒé…ç½®
- âœ… è¿è¡Œ2è½®å¿«é€Ÿè®­ç»ƒéªŒè¯
- âœ… ç¡®ä¿æ•°æ®ä¸‹è½½å’ŒåŠ è½½æ­£å¸¸

### ğŸ å¯åŠ¨è®­ç»ƒ

#### ğŸ¯ æ™ºèƒ½ä¼˜åŒ–æ¨¡å¼ï¼ˆæ¨èï¼‰

```bash
python train.py
```

**ç‰¹ç‚¹**:

- ğŸ§  è‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶é…ç½®
- âš¡ æ™ºèƒ½é€‰æ‹©æ¨¡å‹å’Œå‚æ•°
- ğŸ“Š å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
- ğŸ’¾ è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹

#### ğŸ›ï¸ è‡ªå®šä¹‰å‚æ•°æ¨¡å¼

```bash
# é•¿æ—¶é—´è®­ç»ƒ
python train.py --epochs 100

# æŒ‡å®šè¾“å‡ºç›®å½•
python train.py --out-dir runs/my_experiment

# æ‰‹åŠ¨æŒ‡å®šæ‰¹æ¬¡å¤§å°
python train.py --batch-size 256 --num-workers 8

# ç¦ç”¨è‡ªåŠ¨ä¼˜åŒ–ï¼Œå®Œå…¨æ‰‹åŠ¨æ§åˆ¶
python train.py --disable-auto --batch-size 128 --lr 0.01
```

#### ğŸ“‹ å¸¸ç”¨å‘½ä»¤å‚æ•°

| å‚æ•°               | é»˜è®¤å€¼                 | è¯´æ˜           |
| ------------------ | ---------------------- | -------------- |
| `--epochs`       | 50                     | è®­ç»ƒè½®æ•°       |
| `--batch-size`   | è‡ªåŠ¨                   | æ‰¹æ¬¡å¤§å°       |
| `--lr`           | 0.1                    | åˆå§‹å­¦ä¹ ç‡     |
| `--num-workers`  | è‡ªåŠ¨                   | æ•°æ®åŠ è½½è¿›ç¨‹æ•° |
| `--out-dir`      | runs/cifar10_optimized | è¾“å‡ºç›®å½•       |
| `--data-dir`     | data                   | æ•°æ®é›†ç›®å½•     |
| `--disable-auto` | False                  | ç¦ç”¨æ™ºèƒ½ä¼˜åŒ–   |
| `--weight-decay` | 1e-4                   | L2æ­£åˆ™åŒ–ç³»æ•°   |

### ğŸ“Š è®­ç»ƒè¾“å‡ºè§£è¯»

è®­ç»ƒå¼€å§‹åï¼Œæ‚¨ä¼šçœ‹åˆ°å¦‚ä¸‹è¾“å‡ºæ ¼å¼ï¼š

```
--- [1/10] è®­ç»ƒå¯åŠ¨ ---
[ç¡¬ä»¶æ£€æµ‹] GPUæ•°é‡: 2
[ç¡¬ä»¶æ£€æµ‹] GPU 0: NVIDIA GeForce RTX 3090 (24.0GB)
[ç¡¬ä»¶æ£€æµ‹] GPU 1: NVIDIA GeForce RTX 3090 (24.0GB)
[ç¡¬ä»¶æ£€æµ‹] æ€»æ˜¾å­˜: 48.0GB
[ç¡¬ä»¶æ£€æµ‹] æ¨èæ‰¹æ¬¡å¤§å°: 384
[ç¡¬ä»¶æ£€æµ‹] æ¨èworkeræ•°: 12
[GPUä¼˜åŒ–] è‡ªåŠ¨é€‰æ‹©ç»„åˆ: NVIDIA GeForce RTX 3090 (å…± 2 å¼ )
--- [4/10] ä¸»è®¾å¤‡å˜æ›´ä¸º cuda:0, æ¨¡å‹å·²ç§»è‡³è¯¥GPU ---
--- [5/10] DataParallel æ¨¡å‹åŒ…è£…å®Œæˆ, ä½¿ç”¨è®¾å¤‡: [0, 1] ---
[æ¨¡å‹é€‰æ‹©] ä½¿ç”¨PowerCifarNet (ä¸­ç­‰æ¨¡å‹)
--- [6/10] æ¨¡å‹å‚æ•°é‡: 4,234,826 ---

Epoch [1/50] | Batch [100/391] | Loss: 1.234 | Acc: 45.67% | LR: 0.0950 | GPU Mem: 8.2GB
```

### ğŸ¯ è®­ç»ƒæˆåŠŸæ ‡å¿—

è®­ç»ƒæ­£å¸¸è¿›è¡Œæ—¶ï¼Œæ‚¨åº”è¯¥çœ‹åˆ°ï¼š

- âœ… GPUå†…å­˜å ç”¨ç¨³å®šï¼ˆä¸ä¼šæŒç»­å¢é•¿ï¼‰
- âœ… æŸå¤±å€¼é€æ­¥ä¸‹é™
- âœ… å‡†ç¡®ç‡é€æ­¥æå‡ï¼ˆé€šå¸¸30è½®åèƒ½è¾¾åˆ°85%+ï¼‰
- âœ… å­¦ä¹ ç‡æŒ‰è®¡åˆ’è°ƒæ•´
- âœ… æ— CUDAé”™è¯¯æˆ–å†…å­˜æº¢å‡º

## ğŸ—ï¸ æ ¸å¿ƒè®¾è®¡ç†å¿µä¸æŠ€æœ¯æ¶æ„

### ğŸ¯ è®¾è®¡å“²å­¦ï¼šè®©AIè®­ç»ƒå˜å¾—æ™ºèƒ½

æœ¬é¡¹ç›®çš„æ ¸å¿ƒè®¾è®¡ç†å¿µæ˜¯**"æ™ºèƒ½è‡ªé€‚åº”"**ï¼Œå³è®©æ·±åº¦å­¦ä¹ è®­ç»ƒç³»ç»Ÿèƒ½å¤Ÿï¼š

- ğŸ§  **è‡ªä¸»æ€è€ƒ**: è‡ªåŠ¨åˆ†æç¡¬ä»¶ç¯å¢ƒï¼Œæ— éœ€äººå·¥é…ç½®
- âš¡ **åŠ¨æ€é€‚åº”**: æ ¹æ®å®é™…æ¡ä»¶é€‰æ‹©æœ€ä¼˜ç­–ç•¥
- ğŸ› ï¸ **ç¨³å¥è¿è¡Œ**: é¢å¯¹å¤æ‚ç¯å¢ƒæ—¶ä¿æŒç¨³å®šæ€§
- ğŸ“ˆ **æ€§èƒ½æœ€ä¼˜**: åœ¨ä»»ä½•ç¡¬ä»¶é…ç½®ä¸‹éƒ½èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½

### ğŸš€ æŠ€æœ¯

#### 1. GPUè°ƒåº¦ç®—æ³•

**æ ¸å¿ƒé—®é¢˜**: æ··åˆGPUç¯å¢ƒä¸‹çš„æ€§èƒ½ç“¶é¢ˆ

```python
# ä¼ ç»Ÿæ–¹æ¡ˆçš„é—®é¢˜
device_ids = [0, 1, 2]  # åŒ…å«A6000(cuda:0) + 3090(cuda:1,2)
# ç»“æœï¼šæ€§èƒ½è¢«æœ€æ…¢çš„GPUé™åˆ¶ï¼Œå‡ºç°ä¸¥é‡ä¸å¹³è¡¡
```

**æ–¹æ¡ˆ**:

```python
def intelligent_gpu_grouping(gpu_names):
    """æ™ºèƒ½GPUåˆ†ç»„ç®—æ³•"""
    # 1. ç»Ÿè®¡å„å‹å·GPUæ•°é‡
    gpu_counts = Counter(gpu_names)
  
    # 2. é€‰æ‹©æ•°é‡æœ€å¤šçš„åŒå‹å·GPU
    most_common_gpu = gpu_counts.most_common(1)[0][0]
    device_ids = [i for i, name in enumerate(gpu_names) if name == most_common_gpu]
  
    # 3. è®¾ç½®ä¸»è®¾å¤‡ä¸ºè¯¥ç»„çš„ç¬¬ä¸€ä¸ªGPU
    master_device = f"cuda:{device_ids[0]}"
  
    return device_ids, master_device
```

**æŠ€æœ¯ä¼˜åŠ¿**:

- âœ… æ¶ˆé™¤æ··åˆGPUæ€§èƒ½ç“¶é¢ˆ
- âœ… ä¿è¯è®­ç»ƒåŒæ­¥æ€§
- âœ… æœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡
- âœ… é¿å…CUDAé€šä¿¡å¤±è´¥

#### 2. è‡ªé€‚åº”æ¨¡å‹æ¶æ„è®¾è®¡

**è®¾è®¡ç†å¿µ**: è®©æ¨¡å‹è§„æ¨¡åŒ¹é…ç¡¬ä»¶èƒ½åŠ›

##### SmallCifarNet (è½»é‡çº§æ¶æ„)

```python
# å‚æ•°é‡: ~1.2M
# é€‚ç”¨åœºæ™¯: å•GPUã€ä½æ˜¾å­˜ã€å¿«é€ŸéªŒè¯
Architecture:
Input(3,32,32) 
â†’ Conv2d(32) + BN + ReLU + MaxPool 
â†’ Conv2d(64) + BN + ReLU + MaxPool 
â†’ Conv2d(128) + BN + ReLU + MaxPool 
â†’ FC(512) â†’ FC(10)
```

##### PowerCifarNet (é«˜æ€§èƒ½æ¶æ„)

```python
# å‚æ•°é‡: 2M-10M+ (å¯è°ƒèŠ‚)
# é€‚ç”¨åœºæ™¯: å¤šGPUã€å¤§æ˜¾å­˜ã€é«˜ç²¾åº¦éœ€æ±‚
Architecture:
Input(3,32,32) 
â†’ [Conv2d + Conv2d + BN + ReLU + MaxPool + Dropout2d] Ã— 4ç»„
â†’ AdaptiveAvgPool2d 
â†’ [FC + Dropout] Ã— 3å±‚ â†’ FC(10)

# width_multå‚æ•°æ§åˆ¶æ¨¡å‹å¤§å°
base_channels = int(64 * width_mult)
```

**æ™ºèƒ½é€‰æ‹©ç­–ç•¥**:

```python
def select_optimal_model(num_gpus, total_memory_gb):
    if num_gpus >= 3 and total_memory_gb >= 60:
        return PowerCifarNet(width_mult=2.5)  # å¤§å‹é…ç½®
    elif num_gpus >= 2 or total_memory_gb >= 40:
        return PowerCifarNet(width_mult=1.5)  # ä¸­å‹é…ç½®  
    else:
        return SmallCifarNet()  # è½»é‡é…ç½®
```

#### 3. å‚æ•°è‡ªé€‚åº”ä¼˜åŒ–ç³»ç»Ÿ

**æ‰¹æ¬¡å¤§å°æ™ºèƒ½æ¨è**:

```python
def recommend_batch_size(total_memory_gb, num_gpus):
    """åŸºäºæ˜¾å­˜å’ŒGPUæ•°é‡çš„æ‰¹æ¬¡å¤§å°æ¨èç®—æ³•"""
    if total_memory_gb >= 60:    # 3x RTX 3090 çº§åˆ«
        return 512
    elif total_memory_gb >= 40:  # 2x RTX 3080 çº§åˆ«  
        return 384
    elif total_memory_gb >= 20:  # 1x RTX 3080 çº§åˆ«
        return 256
    else:                        # å…¥é—¨çº§GPU
        return 128
```

**å­¦ä¹ ç‡åŠ¨æ€ç¼©æ”¾**:

```python
# éµå¾ªçº¿æ€§ç¼©æ”¾è§„åˆ™
scaled_lr = base_lr * sqrt(batch_size / base_batch_size)
# ç¡®ä¿å¤§æ‰¹æ¬¡è®­ç»ƒçš„ç¨³å®šæ€§
```

#### 4. æ•°æ®åŠ è½½ä¼˜åŒ–ç­–ç•¥

**é«˜æ€§èƒ½æ•°æ®ç®¡é“**:

```python
DataLoader(
    dataset, 
    batch_size=batch_size,
    num_workers=auto_workers,        # è‡ªåŠ¨è®¡ç®—æœ€ä¼˜è¿›ç¨‹æ•°
    pin_memory=True,                 # GPUç›´æ¥å†…å­˜è®¿é—®
    persistent_workers=True,         # ä¿æŒworkerè¿›ç¨‹æ´»è·ƒ
    prefetch_factor=4,               # é¢„å–4ä¸ªæ‰¹æ¬¡
)
```

#### 5. ç¨³å®šæ€§ä¿éšœæœºåˆ¶

**æ··åˆç²¾åº¦è®­ç»ƒ**:

```python
# è‡ªåŠ¨å¯ç”¨AMPï¼Œæé«˜è®­ç»ƒé€Ÿåº¦å’Œæ˜¾å­˜åˆ©ç”¨ç‡
with torch.cuda.amp.autocast():
    output = model(input)
    loss = criterion(output, target)
```

**ç¯å¢ƒå˜é‡ä¼˜åŒ–**:

```python
# è§£å†³å¤šGPUé€šä¿¡é—®é¢˜
os.environ['NCCL_P2P_DISABLE'] = '1'   # ç¦ç”¨P2Pé€šä¿¡
os.environ['NCCL_IB_DISABLE'] = '1'     # ç¦ç”¨InfiniBand
```

**å†…å­˜ç®¡ç†**:

```python
# ä¼˜åŒ–CUDAå†…å­˜åˆ†é…
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
torch.backends.cudnn.benchmark = True   # ä¼˜åŒ–å·ç§¯ç®—æ³•é€‰æ‹©
```

### ğŸ¨ æ•°æ®å¢å¼ºç­–ç•¥

**å¹³è¡¡å¢å¼ºæ–¹æ¡ˆ**ï¼ˆé¿å…è¿‡åº¦æ­£åˆ™åŒ–ï¼‰:

```python
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),      # éšæœºè£å‰ª
    transforms.RandomHorizontalFlip(),         # æ°´å¹³ç¿»è½¬
    transforms.ToTensor(),       
    transforms.Normalize([0.4914, 0.4822, 0.4465], 
                        [0.2023, 0.1994, 0.2010]),  # CIFAR-10æ ‡å‡†åŒ–
    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2)),  # è½»åº¦éšæœºæ“¦é™¤
])
```

**è®¾è®¡åŸåˆ™**:

- âœ… ä¿è¯æ¨¡å‹èƒ½å­¦åˆ°æ ¸å¿ƒç‰¹å¾
- âœ… é¿å…è¿‡åº¦å¢å¼ºå¯¼è‡´çš„æ”¶æ•›å›°éš¾
- âœ… å¹³è¡¡æ³›åŒ–èƒ½åŠ›ä¸è®­ç»ƒç¨³å®šæ€§

## ğŸ› ï¸ é—®é¢˜è¯Šæ–­ä¸è§£å†³æ–¹æ¡ˆ

### ğŸ“Š é—®é¢˜åˆ†ç±»ä¸è§£å†³ç­–ç•¥

#### ğŸš¨ ç±»åˆ«1ï¼šGPUå…¼å®¹æ€§é—®é¢˜

##### é—®é¢˜1: æ··åˆGPUå¯¼è‡´å¯åŠ¨å¡é¡¿æˆ–ç¨‹åºæŒ‚æ­»

**ç°è±¡æè¿°**:

```bash
--- [1/10] è®­ç»ƒå¯åŠ¨ ---
[ç¡¬ä»¶æ£€æµ‹] GPUæ•°é‡: 3
[ç¡¬ä»¶æ£€æµ‹] GPU 0: NVIDIA RTX A6000 (48.0GB)
[ç¡¬ä»¶æ£€æµ‹] GPU 1: NVIDIA GeForce RTX 3090 (24.0GB)  
[ç¡¬ä»¶æ£€æµ‹] GPU 2: NVIDIA GeForce RTX 3090 (24.0GB)
# ç¨‹åºåœ¨æ­¤å¤„å¡ä½ï¼Œæ— ä»»ä½•è¾“å‡ºï¼ŒGPUåˆ©ç”¨ç‡ä¸º0%
```

**æ·±åº¦åŸå› åˆ†æ**:

```python
# é—®é¢˜çš„æŠ€æœ¯æ ¹æº
1. P2Pé€šä¿¡å¤±è´¥:
   - A6000 (Ampereæ¶æ„) vs RTX 3090 (Ampereæ¶æ„)
   - ä¸åŒçš„PCIeæ‹“æ‰‘ç»“æ„å¯¼è‡´P2Pé€šä¿¡åˆå§‹åŒ–è¶…æ—¶
   - NCCLé»˜è®¤å°è¯•ä½¿ç”¨é«˜é€Ÿé€šä¿¡ï¼Œä½†æ··åˆç¯å¢ƒä¸‹å¯èƒ½ä¸å…¼å®¹

2. å†…å­˜æ‹“æ‰‘ä¸åŒ¹é…:
   - A6000: 48GBæ˜¾å­˜ï¼Œä¸åŒçš„å†…å­˜æ§åˆ¶å™¨
   - RTX 3090: 24GBæ˜¾å­˜
   - DataParallelå‡è®¾æ‰€æœ‰è®¾å¤‡å†…å­˜ç»“æ„ç›¸åŒ

3. ä¸»è®¾å¤‡è°ƒåº¦é”™è¯¯:
   - é»˜è®¤ä½¿ç”¨cuda:0(A6000)ä½œä¸ºå‚æ•°æœåŠ¡å™¨
   - ä½†å®é™…è®¡ç®—åˆ†é…ç»™cuda:1,2(RTX 3090)
   - è·¨æ¶æ„çš„æ•°æ®ä¼ è¾“äº§ç”Ÿä¸¥é‡ç“¶é¢ˆ
```

**è§£å†³æ–¹æ¡ˆ**:

```python
# 1. ç¯å¢ƒå˜é‡ä¼˜åŒ– (å¿…é¡»åœ¨å¯¼å…¥torchä¹‹å‰è®¾ç½®)
os.environ['NCCL_P2P_DISABLE'] = '1'      # ç¦ç”¨P2Pç›´è¿
os.environ['NCCL_IB_DISABLE'] = '1'       # ç¦ç”¨InfiniBand
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'   # åŒæ­¥CUDAè°ƒç”¨(debugç”¨)

# 2. æ™ºèƒ½GPUåˆ†ç»„ç®—æ³•
def resolve_mixed_gpu_issue():
    gpu_names = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]
    gpu_counts = Counter(gpu_names)
  
    # è‡ªåŠ¨é€‰æ‹©æ•°é‡æœ€å¤šçš„åŒç§GPU
    most_common_gpu = gpu_counts.most_common(1)[0][0]
    device_ids = [i for i, name in enumerate(gpu_names) if name == most_common_gpu]
  
    print(f"[GPUä¼˜åŒ–] é€‰ä¸­: {most_common_gpu} Ã— {len(device_ids)}")
    print(f"[GPUä¼˜åŒ–] å¿½ç•¥: {set(range(len(gpu_names))) - set(device_ids)}")
  
    return device_ids

# 3. æ­£ç¡®çš„ä¸»è®¾å¤‡è®¾ç½®
device_ids = resolve_mixed_gpu_issue()
main_device = torch.device(f"cuda:{device_ids[0]}")
model.to(main_device)  # å…ˆç§»åŠ¨æ¨¡å‹åˆ°ä¸»è®¾å¤‡
model = nn.DataParallel(model, device_ids=device_ids)
```

#### ğŸ”¥ ç±»åˆ«2ï¼šè®­ç»ƒç¨³å®šæ€§é—®é¢˜

##### é—®é¢˜2: è®­ç»ƒæ›²çº¿å‰§çƒˆéœ‡è¡ï¼Œæ”¶æ•›å›°éš¾

**ç°è±¡æè¿°**:

```
Epoch [5/50] | Loss: 1.456 | Acc: 45.2%
Epoch [6/50] | Loss: 1.623 | Acc: 38.9%  # å‡†ç¡®ç‡ä¸‹é™
Epoch [7/50] | Loss: 1.334 | Acc: 51.3%  # åˆä¸Šå‡
Epoch [8/50] | Loss: 1.789 | Acc: 33.1%  # å†æ¬¡ä¸‹é™
```

**æ·±åº¦åŸå› åˆ†æ**:

```python
# æ—©æœŸç‰ˆæœ¬çš„è¿‡åº¦ä¼˜åŒ–é—®é¢˜
problems = {
    "æ•°æ®å¢å¼ºè¿‡å¼º": [
        "RandomRotation(degrees=30)",        # æ—‹è½¬è¿‡å¤§
        "ColorJitter(0.8, 0.8, 0.8, 0.2)",  # é¢œè‰²æ‰­æ›²è¿‡å¼º
        "RandomErasing(p=0.7)",              # æ“¦é™¤æ¦‚ç‡è¿‡é«˜
        "åŒæ—¶ä½¿ç”¨å¤šç§å¼ºå¢å¼º"                    # å åŠ æ•ˆåº”
    ],
    "å­¦ä¹ ç‡è°ƒåº¦æ¿€è¿›": [
        "OneCycleLR(max_lr=0.5)",            # æœ€å¤§å­¦ä¹ ç‡è¿‡é«˜
        "å¿«é€Ÿè¡°å‡åˆ°æå°å€¼",                    # è¡°å‡è¿‡å¿«
        "æ²¡æœ‰warm-upé˜¶æ®µ"                    # ç¼ºå°‘é¢„çƒ­
    ],
    "æ‰¹æ¬¡å¤§å°ä¸åŒ¹é…": [
        "å¤§æ‰¹æ¬¡ + é«˜å­¦ä¹ ç‡",                  # ç»„åˆä¸å½“
        "æ²¡æœ‰è€ƒè™‘GPUæ˜¾å­˜é™åˆ¶",                # è¶…å‡ºç¡¬ä»¶èƒ½åŠ›
    ]
}
```

**ä¼˜åŒ–åçš„ç¨³å®šæ–¹æ¡ˆ**:

```python
# 1. å¹³è¡¡çš„æ•°æ®å¢å¼º
train_transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),        # é€‚åº¦è£å‰ª
    transforms.RandomHorizontalFlip(p=0.5),      # 50%ç¿»è½¬æ¦‚ç‡
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                        std=[0.2023, 0.1994, 0.2010]),
    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2))  # é™ä½æ“¦é™¤å¼ºåº¦
])

# 2. ç¨³å®šçš„å­¦ä¹ ç‡è°ƒåº¦
def get_stable_scheduler(optimizer, epochs, batch_size):
    if batch_size >= 256:
        # å¤§æ‰¹æ¬¡ä½¿ç”¨ä½™å¼¦é€€ç«
        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    else:
        # å°æ‰¹æ¬¡ä½¿ç”¨é˜¶æ¢¯è¡°å‡
        return torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)

# 3. è‡ªé€‚åº”å­¦ä¹ ç‡ç¼©æ”¾
base_lr = 0.1
scaled_lr = base_lr * math.sqrt(batch_size / 128)  # å¹³æ–¹æ ¹ç¼©æ”¾æ›´ç¨³å®š
```

## ğŸš€ å‚æ•°è°ƒä¼˜

### âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 1. æ‰¹æ¬¡å¤§å°ä¼˜åŒ–ç­–ç•¥

```python
def find_optimal_batch_size(model, device, start_size=32):
    """åŠ¨æ€å¯»æ‰¾æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
    batch_size = start_size
    max_batch_size = 2048
  
    print(f"[ä¼˜åŒ–] å¼€å§‹å¯»æ‰¾æœ€ä¼˜æ‰¹æ¬¡å¤§å°...")
  
    while batch_size <= max_batch_size:
        try:
            # æ¨¡æ‹Ÿè®­ç»ƒè´Ÿè½½
            dummy_input = torch.randn(batch_size, 3, 32, 32).to(device)
            dummy_target = torch.randint(0, 10, (batch_size,)).to(device)
  
            # æ¸…ç©ºç¼“å­˜
            torch.cuda.empty_cache()
  
            # æµ‹è¯•å‰å‘+åå‘ä¼ æ’­
            with torch.cuda.amp.autocast():
                output = model(dummy_input)
                loss = F.cross_entropy(output, dummy_target)
                loss.backward()
  
            # è®°å½•æˆåŠŸçš„æ‰¹æ¬¡å¤§å°
            successful_batch_size = batch_size
            print(f"[ä¼˜åŒ–] âœ… æ‰¹æ¬¡å¤§å° {batch_size} å¯è¡Œ")
  
            # å°è¯•æ›´å¤§çš„æ‰¹æ¬¡
            batch_size *= 2
  
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"[ä¼˜åŒ–] ğŸ“Š æœ€ä¼˜æ‰¹æ¬¡å¤§å°: {successful_batch_size}")
                return successful_batch_size
            else:
                raise e
  
    return successful_batch_size

# ä½¿ç”¨æ–¹æ³•
optimal_batch_size = find_optimal_batch_size(model, device)
```

#### 2. å­¦ä¹ ç‡è°ƒåº¦ä¼˜åŒ–

```python
def create_advanced_scheduler(optimizer, total_epochs, batch_size):
    """åˆ›å»ºé«˜çº§å­¦ä¹ ç‡è°ƒåº¦å™¨"""
  
    if batch_size >= 256:
        # å¤§æ‰¹æ¬¡ï¼šä½¿ç”¨å¸¦é‡å¯çš„ä½™å¼¦é€€ç«
        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
            optimizer, 
            T_0=10,      # ç¬¬ä¸€æ¬¡é‡å¯å‘¨æœŸ
            T_mult=2,    # æ¯æ¬¡é‡å¯å‘¨æœŸç¿»å€
            eta_min=1e-6 # æœ€å°å­¦ä¹ ç‡
        )
        print("[è°ƒåº¦å™¨] ä½¿ç”¨CosineAnnealingWarmRestarts (å¤§æ‰¹æ¬¡ä¼˜åŒ–)")
  
    elif batch_size >= 128:
        # ä¸­ç­‰æ‰¹æ¬¡ï¼šæ ‡å‡†ä½™å¼¦é€€ç«
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=total_epochs,
            eta_min=1e-6
        )
        print("[è°ƒåº¦å™¨] ä½¿ç”¨CosineAnnealingLR (ä¸­ç­‰æ‰¹æ¬¡)")
  
    else:
        # å°æ‰¹æ¬¡ï¼šå¤šæ­¥è¡°å‡
        scheduler = torch.optim.lr_scheduler.MultiStepLR(
            optimizer,
            milestones=[int(0.6 * total_epochs), int(0.8 * total_epochs)],
            gamma=0.1
        )
        print("[è°ƒåº¦å™¨] ä½¿ç”¨MultiStepLR (å°æ‰¹æ¬¡)")
  
    return scheduler
```

#### 3. æ··åˆç²¾åº¦è®­ç»ƒä¼˜åŒ–

```python
class AdvancedMixedPrecisionTrainer:
    """é«˜çº§æ··åˆç²¾åº¦è®­ç»ƒå™¨"""
  
    def __init__(self, model, optimizer):
        self.model = model
        self.optimizer = optimizer
        self.scaler = torch.cuda.amp.GradScaler(
            init_scale=2**16,     # åˆå§‹ç¼©æ”¾å› å­
            growth_factor=2.0,    # ç¼©æ”¾å› å­å¢é•¿ç‡
            backoff_factor=0.5,   # ç¼©æ”¾å› å­å›é€€ç‡
            growth_interval=2000  # å¢é•¿æ£€æŸ¥é—´éš”
        )
  
    def train_step(self, inputs, targets):
        self.optimizer.zero_grad()
  
        # å‰å‘ä¼ æ’­ (è‡ªåŠ¨æ··åˆç²¾åº¦)
        with torch.cuda.amp.autocast():
            outputs = self.model(inputs)
            loss = F.cross_entropy(outputs, targets)
  
        # åå‘ä¼ æ’­ (ç¼©æ”¾æ¢¯åº¦)
        self.scaler.scale(loss).backward()
  
        # æ¢¯åº¦è£å‰ª (é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸)
        self.scaler.unscale_(self.optimizer)
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
  
        # ä¼˜åŒ–å™¨æ­¥è¿›
        self.scaler.step(self.optimizer)
        self.scaler.update()
  
        return loss.item()
```

#### 4. æ•°æ®åŠ è½½ä¼˜åŒ–

```python
class UltraFastDataLoader:
    """è¶…é«˜æ€§èƒ½æ•°æ®åŠ è½½å™¨"""
  
    def __init__(self, dataset, batch_size, num_workers=None):
        if num_workers is None:
            # æ™ºèƒ½è®¡ç®—æœ€ä¼˜workeræ•°é‡
            num_workers = min(batch_size // 32, os.cpu_count(), 16)
  
        self.dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,              # GPUå†…å­˜é”å®š
            persistent_workers=True,      # ä¿æŒworkerè¿›ç¨‹
            prefetch_factor=8,            # å¢åŠ é¢„å–ç¼“å†²
            drop_last=True,              # ä¿æŒæ‰¹æ¬¡ä¸€è‡´
            generator=torch.Generator().manual_seed(42)  # å¯é‡ç°éšæœºæ€§
        )
  
        print(f"[æ•°æ®åŠ è½½å™¨] Workeræ•°é‡: {num_workers}, é¢„å–å› å­: 8")
  
    def __iter__(self):
        return iter(self.dataloader)
  
    def __len__(self):
        return len(self.dataloader)
```

### ğŸ”§ è¶…å‚æ•°è°ƒä¼˜æŒ‡å—

#### è‡ªåŠ¨è¶…å‚æ•°æœç´¢

```python
def hyperparameter_search(model_class, search_space, num_trials=20):
    """è‡ªåŠ¨è¶…å‚æ•°æœç´¢"""
    import random
  
    best_accuracy = 0
    best_params = None
    results = []
  
    for trial in range(num_trials):
        # éšæœºé‡‡æ ·è¶…å‚æ•°
        params = {
            'lr': random.uniform(*search_space['lr']),
            'batch_size': random.choice(search_space['batch_size']),
            'weight_decay': random.uniform(*search_space['weight_decay']),
            'dropout': random.uniform(*search_space['dropout'])
        }
  
        print(f"\n[æœç´¢] Trial {trial+1}/{num_trials}")
        print(f"[æœç´¢] å‚æ•°: {params}")
  
        # å¿«é€Ÿè®­ç»ƒ (å°‘é‡è½®æ•°)
        model = model_class(dropout=params['dropout'])
        accuracy = quick_train(model, params, epochs=10)
  
        results.append((params, accuracy))
  
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_params = params
            print(f"[æœç´¢] ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {accuracy:.2%}")
  
    return best_params, results

# æœç´¢ç©ºé—´å®šä¹‰
search_space = {
    'lr': [0.01, 0.3],
    'batch_size': [64, 128, 256, 512],
    'weight_decay': [1e-5, 1e-3],
    'dropout': [0.3, 0.7]
}

# æ‰§è¡Œæœç´¢
best_params, all_results = hyperparameter_search(PowerCifarNet, search_space)
```

### ğŸ¯ ä¸åŒåœºæ™¯çš„ä¼˜åŒ–ç­–ç•¥

#### åœºæ™¯1ï¼šå¿«é€ŸéªŒè¯ (5åˆ†é’Ÿå†…å®Œæˆ)

```bash
python train.py --epochs 10 --batch-size 512 --lr 0.2 --out-dir runs/quick_test
```

```python
# å¿«é€ŸéªŒè¯é…ç½®
quick_config = {
    "model": "SmallCifarNet",
    "epochs": 10,
    "batch_size": 512,
    "lr": 0.2,
    "data_augmentation": "minimal",
    "target_accuracy": 75
}
```

#### åœºæ™¯2ï¼šé«˜ç²¾åº¦è®­ç»ƒ (è¿½æ±‚æœ€ä½³æ€§èƒ½)

```bash
python train.py --epochs 200 --batch-size 256 --lr 0.05 --weight-decay 5e-4
```

```python
# é«˜ç²¾åº¦é…ç½®
high_accuracy_config = {
    "model": "PowerCifarNet",
    "width_mult": 2.0,
    "epochs": 200,
    "batch_size": 256,
    "lr": 0.05,
    "scheduler": "CosineAnnealingWarmRestarts",
    "data_augmentation": "heavy",
    "label_smoothing": 0.1,
    "target_accuracy": 96
}
```
